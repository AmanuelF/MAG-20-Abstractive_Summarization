Two human factors studies were conducted to assess the effectiveness of intelligent agents' user interfaces that were designed based on the Situation awareness-based Agent Transparency (SAT) model. Results show that agents' transparency (based on the SAT model) can benefit operator performance and support proper calibration of trust in the agents. Increasing levels of transparency enhanced operator's perceived trust in the agents, but only to a degree. When uncertainty was added to the interface, operator's trust did not further increase. Finally, the subjective workload data suggest that the benefits of increasing agent transparency do not have to be associated with higher levels of operator workload.