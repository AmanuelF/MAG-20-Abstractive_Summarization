Performance of models highly depend not only on the used algorithm but also the data set it was applied to. This makes newly suggested tools difficult to compare, and often requires researchers to implement a previously published algorithm first to have an adequate benchmark on their data set. The Ischemic Stroke Lesion Segmentation (ISLES) challenge, ran now consecutively for three years, aims to address this problem of comparability. ISLES 2016 & 2017 focused on lesion outcome prediction after ischemic stroke. By providing a uniformly pre-processed data set, researchers from all over the world could apply their algorithm directly. A total of nine and 15 research teams participated for ISLES 2016 and ISLES 2017, respectively. Their performance was then evaluated in a fair and transparent way to identify the state-of-the-art amongst all submissions. Top ranked teams almost always employed deep learning tools, which were predominately constitutional neural networks (CNNs). Despite the great efforts, lesion outcome prediction remains a great challenge. The annotated data sets stays publicly available and new approaches can be compared directly via the online evaluation system, serving as a continuing benchmark (www.isles-challenge.org)