Working with others not only improves behavioral efficiency, but also facilitates learning. Such multiagent activity is fundamental to everyday life and, increasingly, virtual and robotic agents are finding a place in these contexts. The effectiveness of human-machine interaction (HMI), however, relies on artificial systems being able to anticipate their partner and select actions that not only lead to achieving the shared goal, but does so efficiently. Here, a multiagent "shepherding" task was used to study coordination and behavior-switching during HMI. The task required the coordinated control of a complex environment, where a non-obvious solution leads to near-optimal task performance. Previous research has demonstrated that a virtual agent, with knowledge of the optimal solution, can effectively steer novices to discover the optimal task behavior [3]. Conversely, results here demonstrate that when completing the task with a virtual avatar incapable of producing this behavior, a subset of novices still discovered and enforced this optimal behavior in the virtual avatar by modulating the sheep-herd's dynamics. These results provide evidence that learning efficient solutions may result from interaction patterns early in the interaction, which may be exploited by adaptive artificial-agents in HMI contexts to facilitate skill acquisition.