The goal of this paper is the development of foundations for robust reasoning and decision-making in pervasively inconsistent theories and deductive databases. The pervasiveness of these inconsistencies is partly inherent to the human epistemic condition (i.e. the need to make decisions on the basis of perspective bound knowledge) and partly inherent to practical limitations (e.g. incomplete knowledge). In the first case, we do not want to eliminate the inconsistencies. In the second case, we cannot eliminate them. So, in both cases, we will have to incorporate them in our descriptions of reasoning and decision making. For this reason, inconsistency handling is one of the central problems in many areas of AI. There are different approaches to dealing with contradictions and other types of inconsistency. In this paper, we develop an approach based on logical varieties and prevarieties, which are complex structures constructed from logical calculi. Being locally isomorphic to a logical calculus, globally logical varieties form a logical structure, which allows representation of inconsistent knowledge in a consistent way and provides much more flexibility and efficacy for AI than standard logical methods. Logical varieties and prevarieties are efficiently used in database theory and practice, expert systems and knowledge representation and processing. To increase efficiency, flexibility and capabilities of logical varieties and prevarieties and to model perspective bound decision making, we introduce labeling of their elements and study labeled logical varieties and prevarieties. We illustrate the viability of this by an example of a labeled logical variety, the extended Logic of Reasonable Inferences, which is and has been applied in the legal domain.