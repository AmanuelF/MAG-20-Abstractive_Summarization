Autonomous agents have become a powerful paradigm and a subject of a considerable research interest in a great variety of scientific disciplines over the past 20–25 years. Given that the paradigm has been around for a while, one would expect a broadly agreed-upon, solid understanding of what autonomous agents are and what they are not. This, however, does not appear to be the case. We join the debate on what are the appropriate notions of autonomous agency, when applied to artificial agents (in particular, to software, robotic, unmanned vehicle and other engineered systems). To support the proposed notions of autonomous agency, we draw on both computational and biological paradigms. We discuss different approaches to understanding and classifying various types of artificial autonomous agents. In that context, we point out certain dangers of what we see as excessive “anthropomorphization” of (artificial) autonomous agents and agent systems, namely, the common practice of casually assigning anthropomorphic features (and, in particular, advanced properties of human cognition) to various engineered agent systems. As an alternative, we propose a functionalist, cybernetics and general systems theory inspired approach to characterizing various types of autonomous agents in terms of their core attributes or capabilities, as evidenced and testable by an external observer. We argue that such functionalist and behaviorist view of (artificial) autonomous agents provides a conceptually more natural, more compelling and practically more useful framework for understanding various autonomous agent systems and their classifications, including but not limited to the hierarchical taxonomy of autonomous agents that we propose.